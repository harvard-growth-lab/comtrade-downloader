{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd643f05-fb41-4d9d-94cb-6675ab29db8d",
   "metadata": {},
   "source": [
    "Utility file to validate downloaded raw Comtrade folders are complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d799f2-f455-485b-ab57-df643b911d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from downloader import ComtradeDownloader, API_KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b6416e-772c-42cb-ad86-7e610abb9a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import comtradeapicall\n",
    "import glob\n",
    "\n",
    "%load_ext jupyter_black\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.set_option(\"max_colwidth\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016c2cb2-6888-4f24-b583-e761784723f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for 2023 in S2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2021: [], 2022: []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generates dictionary with a list of all missing reporters that have data for a given year\n",
    "\n",
    "# ENTER IN DATA INPUTS\n",
    "year_start = 2021\n",
    "year_end = 2023\n",
    "classification_code = \"S2\"\n",
    "\n",
    "output_dir = \"/n/hausmann_lab/lab/atlas/data/\"\n",
    "raw_files_path = os.path.join(output_dir, \"raw\", classification_code)\n",
    "\n",
    "\n",
    "def partially_downloaded_list(year_start, year_end):\n",
    "    \"\"\"\n",
    "    Get information about last date raw files for the classification code\n",
    "    and year were last downloaded\n",
    "    \"\"\"\n",
    "    partial_dict = {}\n",
    "    for year in range(year_start, year_end + 1):\n",
    "        raw_file_by_year_path = os.path.join(raw_files_path, str(year))\n",
    "        df = comtradeapicall.getFinalDataBulkAvailability(\n",
    "            API_KEYS[\"Ellie\"],\n",
    "            typeCode=\"C\",\n",
    "            freqCode=\"A\",\n",
    "            clCode=classification_code,\n",
    "            period=str(year),\n",
    "            reporterCode=None,\n",
    "        )\n",
    "        if df.empty:\n",
    "            print(f\"No data for {year} in {classification_code}\")\n",
    "            continue\n",
    "        available_reporters = df[[\"reporterCode\"]][\"reporterCode\"].tolist()\n",
    "        for file in glob.glob(os.path.join(raw_file_by_year_path, \"*.gz\")):\n",
    "            # from file title, char 27:37 extract most recently updated date\n",
    "            reporter_code = int(file.split(\"/\")[-1][17:20])\n",
    "            try:\n",
    "                index_to_delete = available_reporters.index(reporter_code)\n",
    "                del available_reporters[index_to_delete]\n",
    "            except ValueError as e:\n",
    "                print(f\"{reporter_code} not in available reporters for year {year}\")\n",
    "                print(e)\n",
    "        partial_dict[year] = available_reporters\n",
    "\n",
    "    return partial_dict\n",
    "\n",
    "\n",
    "partial_dict = partially_downloaded_list(year_start, year_end)\n",
    "partial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da97ac30-63a9-4fd0-a948-087cea59ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on remaining files left to download identified by above function\n",
    "# One year at a time, enter the year and complete the download for that year\n",
    "\n",
    "classification_code = \"S2\"\n",
    "year = 2021\n",
    "\n",
    "output_dir = \"/n/hausmann_lab/lab/atlas/data/\"\n",
    "raw_files_path = os.path.join(output_dir, \"raw\", classification_code)\n",
    "\n",
    "for reporter_code in partial_dict[year]:\n",
    "    comtradeapicall.bulkDownloadFinalFile(\n",
    "        API_KEYS[\"Brendan\"],\n",
    "        os.path.join(raw_files_path, str(year)),\n",
    "        typeCode=\"C\",\n",
    "        freqCode=\"A\",\n",
    "        clCode=classification_code,\n",
    "        period=str(year),\n",
    "        reporterCode=str(reporter_code),\n",
    "        decompress=False,\n",
    "    )\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953e412f-6561-4208-b777-2cc5ca5aec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletes a directory\n",
    "\n",
    "# import glob\n",
    "# import os\n",
    "# import logging\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# def remove_tmp_dir(tmp_path):\n",
    "#     \"\"\"\n",
    "\n",
    "#     \"\"\"\n",
    "#     for f in glob.glob(os.path.join(tmp_path, \"*.gz\")):\n",
    "#         try:\n",
    "#             os.remove(f)\n",
    "#         except OSError as e:\n",
    "#             logging.info(f\"Error: {f} : {e.strerror}\")\n",
    "\n",
    "#     try:\n",
    "#         os.rmdir(tmp_path)\n",
    "#     except OSError as e:\n",
    "#         logging.info(f\"Error: {tmp_path} : {e.strerror}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62036814-d6c1-48a2-83db-683be8a609d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR  2017\n",
      "Error reading '/n/hausmann_lab/lab/atlas/data/raw/H0/2017/COMTRADE-FINAL-CA7242017H0[2018-08-15].gz': Compressed file ended before the end-of-stream marker was reached\n",
      "Error reading '/n/hausmann_lab/lab/atlas/data/raw/H0/2017/COMTRADE-FINAL-CA7522017H0[2021-11-01].gz': Compressed file ended before the end-of-stream marker was reached\n",
      "Corrupted files:\n",
      "/n/hausmann_lab/lab/atlas/data/raw/H0/2017/COMTRADE-FINAL-CA7242017H0[2018-08-15].gz\n",
      "/n/hausmann_lab/lab/atlas/data/raw/H0/2017/COMTRADE-FINAL-CA7522017H0[2021-11-01].gz\n"
     ]
    }
   ],
   "source": [
    "# check for any corrupted downloaded files given classification code and range of years\n",
    "\n",
    "years = [2017, 2017]\n",
    "\n",
    "corrupted_files = []  # List to store names of corrupted files\n",
    "classification_code = \"H0\"\n",
    "\n",
    "output_dir = \"/n/hausmann_lab/lab/atlas/data/\"\n",
    "\n",
    "for year in range(2017, 2018):\n",
    "    raw_files_path = os.path.join(output_dir, \"raw\", classification_code, str(year))\n",
    "    print(\"YEAR \", year)\n",
    "    for file in glob.glob(os.path.join(raw_files_path, \"*.gz\")):\n",
    "        try:\n",
    "            # Try reading the CSV file with Pandas\n",
    "            pd.read_csv(file)\n",
    "        except Exception as e:\n",
    "            # If an exception occurs, consider the file corrupted and add its name to the list\n",
    "            print(f\"Error reading '{file}': {e}\")\n",
    "            corrupted_files.append(file)\n",
    "\n",
    "if corrupted_files:\n",
    "    print(\"Corrupted files:\")\n",
    "    for corrupted_file in corrupted_files:\n",
    "        print(corrupted_file)\n",
    "else:\n",
    "    print(\"No corrupted files found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
